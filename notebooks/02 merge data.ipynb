{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dc0abac",
   "metadata": {},
   "source": [
    "# OCI Data Science - Merge\n",
    "\n",
    "Before using this notebook user has to download neccessary data. We've collected/downloaded the data in advance by utilizing `00 pull data.ipynb` notebook and saved them to the **data** folder. This helps to save time though data-download may take a few hours.\n",
    "\n",
    "This notebook creates a final dataset, which is utilized for model training and testing. The final data set will include the following features coming from different data sources:\n",
    "1. Track info: Track length, racing laps, track name\n",
    "2. Team info: driver name, positions\n",
    "3. Weather data\n",
    "4. Fuel consumption info: Estimated fuel consumption line's slope and bias\n",
    "5. Tier degradation info: Estimated tire degradation line's slope and bias\n",
    "\n",
    "Compute times reported after execution are based on utilizing compute shape = 2.8 (8 OCPU = 16vcpus)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d732252a",
   "metadata": {},
   "source": [
    "## Contents:\n",
    "* <a href='#intro'>Introduction</a>\n",
    "* <a href='#weatherdata'>Weather Data</a>\n",
    "* <a href='#lapsdata'>Laps Data</a>\n",
    "* <a href='#resultdata'>Results Data</a>\n",
    "* <a href='#Joindata'>Merge Weather and Lap Data</a>\n",
    "* <a href='#plotsamplelapdata'>Plot Sample Lap Data</a>\n",
    "* <a href='#Summarize'>Create Features for Train/Test Data</a>\n",
    "* <a href='#AddTrackInfo'>Merge with Track Info</a>\n",
    "* <a href='#DegLineAndfuelAdjustmnet'>Degradation Line and Fuel Adjustmnet</a>\n",
    "    * <a href='#getLapsData'>Get Laps Data</a>\n",
    "    * <a href='#normalizeFuel'>Calculate Fuel Consumption Line</a>\n",
    "    * <a href='#CalculateDegSlopes'>Calculate Slope of Degradation Line for different Stints</a>\n",
    "* <a href='#mergeLinesSlopAndBias'>Merge Lines' slope and bias</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a48027",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "\n",
    "Data has already been saved in **data** folder. The data that interests us has `.pickle` extension, and are currently in raw format, which means that it requires pre-processing and preparation before performing feature extraction and model building."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee02877e",
   "metadata": {},
   "source": [
    "#### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ed46b734",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/datascience/RedBull-Racining-TimeToPit/notebooks'\n",
    "data_path = '../../RedBull-Racining-TimeToPit/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c131ff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(path)\n",
    "import pandas as pd\n",
    "import logging\n",
    "import json\n",
    "import pickle\n",
    "import requests\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dcfe1f",
   "metadata": {},
   "source": [
    "<a id='weatherdata'></a>\n",
    "## Weather Data\n",
    "Weather data is available at the session level and its timestamp is not aligned with laps-data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7a35b419",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(data_path+'weathers_data.pickle','rb')\n",
    "df_weather = pickle.load(file)\n",
    "df_weather['eventYear'] = pd.DatetimeIndex(df_weather['EventDate']).year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc641ae",
   "metadata": {},
   "source": [
    "<a id='resultdata'></a>\n",
    "## Results\n",
    "\n",
    "Load data and select.\n",
    "\n",
    "Dropping non-race and non-qual rows from results data and keeping the following columns:\n",
    "`'Position','FullName','Q1Sec','Q2Sec','Q3Sec','RoundNumber','EventName','eventYear','session','TimeSec'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "38a42f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------- \n",
      " df_res size is:  (3618, 27) \n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = open(data_path+'results_data.pickle','rb')\n",
    "df_res = pickle.load(file)\n",
    "\n",
    "df_res['eventYear'] = pd.DatetimeIndex(df_res['EventDate']).year\n",
    "df_res['Q1Sec'] = df_res['Q1']/np.timedelta64(1, 's')\n",
    "df_res['Q2Sec'] = df_res['Q2']/np.timedelta64(1, 's')\n",
    "df_res['Q3Sec'] = df_res['Q3']/np.timedelta64(1, 's')\n",
    "df_res['TimeSec'] = df_res['Time']/np.timedelta64(1, 's')\n",
    "\n",
    "\n",
    "## keep only race and qual data\n",
    "df_res = df_res[(df_res['session']=='Race') | (df_res['session']=='Qualifying')]\n",
    "print('-'*100,'\\n', 'df_res size is: ', df_res.shape,'\\n','-'*100,'\\n')\n",
    "print()\n",
    "\n",
    "df_res= df_res[['Position','GridPosition','FullName','Q1Sec','Q2Sec','Q3Sec','RoundNumber','Abbreviation',\n",
    "                'EventName','eventYear','session','Time','TimeSec','TeamName', 'EventDate']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bdfd58",
   "metadata": {},
   "source": [
    "<a id='lapsdata'></a>\n",
    "## Laps Data\n",
    "\n",
    "Load Lap data and convert times to useable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3f7eee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(data_path+'laps_data.pickle','rb')\n",
    "drop_cols = ['Sector1Time','Sector2Time','Sector3Time',\n",
    "             'Sector1SessionTime','Sector2SessionTime','Sector3SessionTime',\n",
    "            'SpeedI1','SpeedI2','SpeedFL', 'IsAccurate']\n",
    "\n",
    "df_laps = pickle.load(file).drop(drop_cols,axis=1).reset_index(drop=True)\n",
    "\n",
    "df_laps['eventYear'] = pd.DatetimeIndex(df_laps['EventDate']).year\n",
    "df_laps['lapTimeSec'] = df_laps['LapTime']/np.timedelta64(1, 's')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1484622",
   "metadata": {},
   "source": [
    "<a id='Joindata'></a>\n",
    "### Merge weather and lap data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "091aaf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Weather and Laps data are not time-aligned and each have their own \n",
    "## \n",
    "df_weather = df_weather.sort_values( ['EventName','eventYear','session', 'Time']).reset_index(drop=True)\n",
    "df_laps = df_laps.sort_values( ['EventName','eventYear','session','Team','Driver', 'Time']).reset_index(drop=True)\n",
    "\n",
    "LapsColumns = ['EventName','eventYear','Team','session','Driver',\n",
    "               'Time', 'DriverNumber', 'LapTime', 'LapNumber', 'Stint', 'PitOutTime',\n",
    "       'PitInTime', 'SpeedST', 'IsPersonalBest', 'Compound', 'TyreLife',\n",
    "       'FreshTyre', 'LapStartTime', 'TrackStatus',\n",
    "       'LapStartDate',  'country', 'EventDate','lapTimeSec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e80569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings # remove warnings temporarily\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def func_merger_lap_weather(d_f):\n",
    "    '''\n",
    "    func_merger_lap_weather method merges weather and laps data\n",
    "    it returns all columns after merge\n",
    "    '''    \n",
    "    \n",
    "    d_f = d_f.sort_values('Time').reset_index(drop=True)\n",
    "    \n",
    "    EventName = np.unique(d_f['EventName'])[0]\n",
    "    session = np.unique(d_f['session'])[0]\n",
    "    eventYear = np.unique(d_f['eventYear'])[0]\n",
    "    Driver = np.unique(d_f['Driver'])\n",
    "    \n",
    "    sub_weather = df_weather[(df_weather['EventName']==EventName) &\n",
    "                            (df_weather['session']==session) &\n",
    "                            (df_weather['eventYear']==eventYear) ].sort_values('Time').reset_index(drop=True)\n",
    "    \n",
    "    sub_result = df_res[(df_weather['EventName']==EventName) &\n",
    "                            (df_weather['session']==session) &\n",
    "                            (df_weather['eventYear']==eventYear) ].sort_values('Time').reset_index(drop=True)\n",
    "    \n",
    "    d_f_merged = pd.merge_asof(d_f, sub_weather, \n",
    "                          on=\"Time\", direction='nearest',\n",
    "                         suffixes=('', '_drop'))\n",
    "    d_f_merged.drop([col for col in d_f_merged.columns if 'drop' in col], axis=1, inplace=True)\n",
    "    \n",
    "#     print(d_f.shape,Driver, len(d_f_merged), EventName , eventYear, np.unique(d_f['Team']), \n",
    "#           session, len(df_weather))\n",
    "    weather_cols = ['WindSpeed', 'AirTemp','Humidity', 'Pressure','TrackTemp','Rainfall','WindDirection']\n",
    "    laps_cols = ['Time', 'DriverNumber', 'LapTime', 'LapNumber', 'Stint', 'PitOutTime', 'RoundNumber',\n",
    "       'PitInTime', 'SpeedST', 'IsPersonalBest', 'Compound', 'TyreLife','FreshTyre', 'LapStartTime', 'TrackStatus',\n",
    "       'LapStartDate',  'country', 'EventDate','lapTimeSec']\n",
    "    laps_cols.extend(weather_cols) \n",
    "    \n",
    "    return  d_f_merged[laps_cols]\n",
    "\n",
    "df_lapWeather = df_laps.groupby(['EventName', 'eventYear','Team','session','Driver'])[LapsColumns].apply(func_merger_lap_weather).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3e9337",
   "metadata": {},
   "source": [
    "<!-- <a id='plotsamplelapdata'></a>\n",
    "### Plot a sample race lap-data -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153248b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_lap = df_lapWeather[(df_lapWeather['EventName']=='Austrian Grand Prix') &\n",
    "#         (df_lapWeather['Team']=='Red Bull Racing') &\n",
    "#         (df_lapWeather['session']=='Race') &\n",
    "#        (df_lapWeather['eventYear']==2019) &\n",
    "#         (df_lapWeather['Driver']=='VER')].sort_values('Time').reset_index(drop=True) #(df_laps['Driver']=='PER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deedd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(12,2))\n",
    "# plt.plot(sub_lap['LapNumber'],sub_lap['lapTimeSec'])\n",
    "# plt.grid()\n",
    "# plt.xlabel('Lap Number')\n",
    "# plt.ylabel('Lap Time (Sec)')\n",
    "# plt.title(sub_lap['EventName'][0]+ '   ' +\n",
    "#           str(sub_lap['eventYear'].values[0])+ '   Driver: ' +\n",
    "#           sub_lap['Driver'][0])\n",
    "\n",
    "# fig = plt.figure(figsize=(12,2))\n",
    "# plt.plot(sub_lap['LapNumber'],sub_lap['AirTemp'])\n",
    "# plt.grid()\n",
    "# plt.xlabel('Lap Number')\n",
    "# plt.ylabel('Temp C')\n",
    "\n",
    "# fig = plt.figure(figsize=(12,2))\n",
    "# plt.plot(sub_lap['LapNumber'],sub_lap['Humidity'])\n",
    "# plt.grid()\n",
    "# plt.xlabel('Lap Number')\n",
    "# plt.ylabel('Humidity %')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5620d7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lapWeather.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb2db11",
   "metadata": {},
   "source": [
    "<a id='Summarize'></a>\n",
    "## Summarize df_lapWeather and add GridPosition/Position: Create Features for Train/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2be7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lapWeatherCols = df_lapWeather.columns\n",
    "\n",
    "def Features_PerTyre_PreRace_PerDriver(sub_df):\n",
    "    \n",
    "    bestTime=sessionName=meanAirTemp=meanTrackTemp=meanHumid=bestLapTimeSession=GridPosition=Position=TyreLife=Rainfall=np.nan  \n",
    "    \n",
    "    raceStintsNums = np.unique(sub_df['Stint'])[0]\n",
    "    raceTyresComps = np.unique(sub_df['Compound'])\n",
    "    Driver = np.unique(sub_df['Driver'])[0]\n",
    "    eventYear = np.unique(sub_df['eventYear'])[0]\n",
    "    EventName = np.unique(sub_df['EventName'])[0]\n",
    "    RoundNumber =  np.unique(sub_df['RoundNumber'])[0]\n",
    "    \n",
    "\n",
    "    \n",
    "    meanAirTemp = np.nanmean(sub_df['AirTemp']) #[sub_df['session']==sessionName] )\n",
    "    meanTrackTemp = np.nanmean(sub_df['TrackTemp']) #[sub_df['session']==sessionName] )\n",
    "    meanHumid = np.nanmean(sub_df['Humidity']) #[sub_df['session']==sessionName] )\n",
    "    Rainfall = np.nanmean(sub_df['Rainfall'])#[sub_df['session']==sessionName] )\n",
    "    \n",
    "    GridPosition = df_res['GridPosition'][\n",
    "                          (df_res['EventName']==EventName)&\n",
    "                          (df_res['eventYear']==eventYear)&\n",
    "                          (df_res['Abbreviation']==Driver)&\n",
    "                          (df_res['RoundNumber']==RoundNumber)&\n",
    "                          (df_res['session']=='Race')]\n",
    "\n",
    "    Position = df_res['Position'][\n",
    "                          (df_res['EventName']==EventName)&\n",
    "                          (df_res['eventYear']==eventYear)&\n",
    "                          (df_res['Abbreviation']==Driver)&\n",
    "                          (df_res['RoundNumber']==RoundNumber)&\n",
    "                          (df_res['session']=='Race')]\n",
    "    if len(GridPosition): \n",
    "        GridPosition=GridPosition.values[0]\n",
    "    if len(Position): \n",
    "        Position=Position.values[0]\n",
    "        \n",
    "    StintLen =[]\n",
    "    StintLen = len(sub_df)\n",
    "#     if len(raceStintsNums):\n",
    "#         for ii in raceStintsNums:\n",
    "#             StintLen.append(len(sub_df[sub_df['Stint']==ii]) )\n",
    "    \n",
    "        \n",
    "    TyreAge = np.min(sub_df['TyreLife'])\n",
    "    lapNumberAtBeginingOfStint = np.min(sub_df['LapNumber'])\n",
    "    \n",
    "    d_f = df_lapWeather[(df_lapWeather['EventName']==EventName)&\n",
    "                        (df_lapWeather['eventYear']==eventYear)&\n",
    "                        (df_lapWeather['Driver']==Driver)&\n",
    "                        (df_lapWeather['RoundNumber']==RoundNumber)&\n",
    "                        (df_lapWeather['session']=='Qualifying')&\n",
    "                        (df_lapWeather['Compound']!='raceTyresComps')]\n",
    "    \n",
    "    if len(d_f)>0:\n",
    "        \n",
    "        bestTime = np.min(d_f['lapTimeSec'])\n",
    "#         print(bestTime, np.unique(d_f['session']) )\n",
    "        \n",
    "        if ~np.isnan(bestTime):\n",
    "            sessionName = np.unique(d_f['session'][d_f['lapTimeSec']==bestTime])[0]\n",
    "         \n",
    "\n",
    "    return pd.Series(data = [bestTime,sessionName, meanAirTemp, meanTrackTemp, meanHumid, Rainfall,\n",
    "                             GridPosition,Position, raceStintsNums,TyreAge,lapNumberAtBeginingOfStint, StintLen], \n",
    "                     index=['bestPreRaceTime','bestLapTimeIsFrom','meanAirTemp','meanTrackTemp','meanHumid','Rainfall', \n",
    "                            'GridPosition','Position','raceStintsNums','TyreAge','lapNumberAtBeginingOfStint', 'StintLen'])\n",
    "\n",
    "df_agg = df_lapWeather[df_lapWeather['session']=='Race'].groupby(['EventName','RoundNumber','eventYear','Team','Compound',\n",
    "                                                            'Driver','Stint']).\\\n",
    "                                                            apply(Features_PerTyre_PreRace_PerDriver).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8c92bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg[df_agg['RoundNumber']==15].reset_index(drop=True).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77bc16a",
   "metadata": {},
   "source": [
    "<a id='AddTrackInfo'></a>\n",
    "## Add track info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f34371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b0db0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load track data\n",
    "trackInfo = pd.read_csv(data_path+'circuit_length.csv')\n",
    "df_agg = df_agg.merge(trackInfo, on=['EventName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87c742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg[df_agg['RoundNumber']==15].reset_index(drop=True).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623bf966",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg.to_csv('../data/semi_final_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91126428",
   "metadata": {},
   "source": [
    "<a id='DegLineAndfuelAdjustmnet'></a>\n",
    "# Tyre Degredation Line and Fuel Adjestmnet\n",
    "\n",
    "Lap data is the primary source of this section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d264d309",
   "metadata": {},
   "source": [
    "## Subjects covered in the rest of this notebook:\n",
    "\n",
    "* <a href='#intro'>Objectives and Introduction</a>\n",
    "* <a href='#process'>Process</a>\n",
    "    * <a href='#getLapsData'>Get Laps Data</a>\n",
    "    * <a href='#normalizeFuel'>Fuel Consumption Rate</a>\n",
    "    * <a href='#CalculateDegSlopes'>Calculate slope of Deg lines for different stints</a>\n",
    "* <a href='#postrocessing'>Postprocessing</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbc65e1",
   "metadata": {},
   "source": [
    "<a id='getLapsData'></a>\n",
    "## get laps Data\n",
    "\n",
    "laps data is already loaded at earlier part of this notebook.\n",
    "In case if user wants to execute the rest of this notebook before running prior cells then the following lines have to executed:\n",
    "\n",
    "`df_agg = pd.read_csv('../data/semi_final_data.csv', index=False)`\n",
    "\n",
    "`file = open(data_path+'laps_data.pickle','rb')`\n",
    "\n",
    "`drop_cols = ['Sector1Time','Sector2Time','Sector3Time',\n",
    "             'Sector1SessionTime','Sector2SessionTime','Sector3SessionTime',\n",
    "            'SpeedI1','SpeedI2','SpeedFL', 'IsAccurate']`\n",
    "\n",
    "`df_laps = pickle.load(file).drop(drop_cols,axis=1).reset_index(drop=True)`\n",
    "\n",
    "`df_laps['eventYear'] = pd.DatetimeIndex(df_laps['EventDate']).year`\n",
    "\n",
    "`df_laps['lapTimeSec'] = df_laps['LapTime']/np.timedelta64(1, 's')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32c06bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_laps.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88efb35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a column to identify laps with a large delat-time between to consequtive laps\n",
    "In normal race condition delat-time between two consequitive laps \n",
    "\"\"\"\n",
    "\n",
    "df_laps['large_delta_time'] = np.nan\n",
    "df_laps['delta_lapTime'] = np.nan\n",
    "\n",
    "\n",
    "## create a column for delta_lapTime'\n",
    "df_laps['delta_lapTime'] = df_laps.groupby(['EventName','eventYear','Driver','session','Stint'])['lapTimeSec'].diff()\n",
    "\n",
    "\n",
    "## label thoes are biger or smaller than +-2\n",
    "df_laps['large_delta_time']= (df_laps['delta_lapTime']<2) & (df_laps['delta_lapTime']>-2)\n",
    "print(sum(df_laps['large_delta_time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba11cc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "## detal-lapTime histogram without filtering\n",
    "fig = plt.figure(figsize=(10,3))\n",
    "sns.histplot(df_laps[df_laps['delta_lapTime'].notnull()],x = 'delta_lapTime', bins=50)\n",
    "plt.title('detal-lapTime histogram')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(10,3))\n",
    "## detal-lapTime histogram with filtering\n",
    "sns.histplot(df_laps[df_laps['large_delta_time']],x = 'delta_lapTime', bins=50)\n",
    "plt.title('detal-lapTime histogram: -2<delta-time<2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf2bc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate Stint length\n",
    "df_stintLen = df_laps.groupby(['EventName','session', 'Driver', 'Stint']).size().reset_index(name='stintLength')\n",
    "df = df_laps.merge(df_stintLen, on = ['EventName','session', 'Driver', 'Stint'])\n",
    "print('-'*100,'\\n', 'df_lap length: ',len(df_laps), '   ','df length is: ', len(df), '\\n','-'*100)\n",
    "\n",
    "## if the stint greater than 5 laps\n",
    "df = df[(df['stintLength']>=6) & (df['session']=='Race')]\n",
    "print('-'*100,'\\n', 'df_lap length: ',len(df_laps), '   ','df length is: ', len(df), '\\n','-'*100)\n",
    "\n",
    "print('-'*100,'\\n', 'Teams are: ',list(np.unique(df['Team']) ), '\\n\\n',\n",
    "      'Event Years are: ', list(np.unique(df['eventYear']) ), '\\n\\n',\n",
    "      'Drivers are: ', list(np.unique(df['Driver']) ), '\\n','-'*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcdc282",
   "metadata": {},
   "source": [
    "<a id='normalizeFuel'></a>\n",
    "### Calculate Fuel Consumption Line\n",
    "It is assumed that at the begining of the race, vehicle is loaded with 100Kg of fuel and at the end of the race the tank is empty.\n",
    "Moreover it is assumed that fuel consumption is linear. we add a col to data for presenting this concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e063560",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def func_fuelLine_sample_points(d_f):\n",
    "    '''\n",
    "    func method return avg of 3 lap-time after Stint and lapNum after Stint\n",
    "    '''    \n",
    "    # Preparing X and y data from the given data\n",
    "    \n",
    "    x = d_f['LapNumber'][(d_f['large_delta_time']) ].values\n",
    "    y = d_f['lapTimeSec'][(d_f['large_delta_time']) ].values\n",
    "\n",
    "    if len(x)<=3: \n",
    "        return pd.Series(data = [np.nan, np.nan], index = ['valueAfterStint','LapNumAfterStint'])\n",
    "    \n",
    "    # Calculating the parameters using the least square method\n",
    "    mean_val = np.mean(y[0:3])\n",
    "    ind = x[0]\n",
    "\n",
    "    return pd.Series(data = [mean_val, ind], index = ['valueAfterStint','LapNumAfterStint'])\n",
    "\n",
    "\n",
    "def func_fuelLine_params(d_f):\n",
    "    '''\n",
    "    func method fits a line to the to the data points (LapNumber, lapTimeSec) \n",
    "    which are collected immediately after each pit\n",
    "    and returns line slope and bias.\n",
    "    '''    \n",
    "    # Preparing X and y data from the given data\n",
    "    d_f.drop_duplicates(subset=['LapNumAfterStint','valueAfterStint'], keep='first', inplace=True)\n",
    "    x = d_f['LapNumAfterStint'].values\n",
    "    y = d_f['valueAfterStint'].values\n",
    "\n",
    "    if (len(x)<2) | sum(np.isnan(x)) | sum(np.isnan(y)): \n",
    "        return pd.Series(data = [np.nan, np.nan], index = ['fuel_slope','fuel_bias'])\n",
    "    \n",
    "    # Calculating the parameters using the least square method\n",
    "    theta = np.polyfit(x, y, 1)\n",
    "    y_line = theta[1] + theta[0] * x\n",
    "\n",
    "    return pd.Series(data = [theta[0], theta[1]], index = ['fuel_slope','fuel_bias'])\n",
    "\n",
    "df_fuel_corr = df.groupby(['EventName','eventYear','session', 'Team','Driver', 'Stint']).apply(func_fuelLine_sample_points).reset_index()\n",
    "df = df.merge(df_fuel_corr, on= ['EventName','eventYear','session', 'Team','Driver', 'Stint'])\n",
    "\n",
    "df_theta = df.groupby(['EventName','eventYear','session', 'Team','Driver']).apply(func_fuelLine_params).reset_index() #name=['theta0','theta1']\n",
    "df = df.merge(df_theta, on= ['EventName','eventYear','session', 'Team','Driver'])\n",
    "\n",
    "print('\\n','-'*100, '\\n','df Length is: ', len(df), '\\n','-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cea105",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b643d8e1",
   "metadata": {},
   "source": [
    "<a id='CalculateDegSlopes'></a>\n",
    "## Calculate slope of deg line for different stints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203b14ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def func_deg_line(d_f):\n",
    "    '''\n",
    "    func method fits a line to the stints' lapTime data and \n",
    "    returns line slope and bias.\n",
    "    '''    \n",
    "    # Preparing X and y data from the given data\n",
    "    \n",
    "    x = d_f['LapNumber'][(d_f['large_delta_time']) ].values\n",
    "    y = d_f['lapTimeSec'][(d_f['large_delta_time']) ].values\n",
    "    \n",
    "    if len(x)<6: \n",
    "        return pd.Series(data = [np.nan, np.nan], index = ['deg_slope','deg_bias'])\n",
    "    \n",
    "    # Calculating the parameters using the least square method\n",
    "    theta = np.polyfit(x[1:-2], y[1:-2], 1)\n",
    "    y_line = theta[1] + theta[0] * x\n",
    "\n",
    "    return pd.Series(data = [theta[0], theta[1]], index = ['deg_slope','deg_bias'])\n",
    "\n",
    "\n",
    "df_theta = df.groupby(['EventName','eventYear','session', 'Team','Driver', 'Stint']).apply(func_deg_line).reset_index() #name=['theta0','theta1']\n",
    "df = df.merge(df_theta, on= ['EventName','eventYear','session', 'Team','Driver', 'Stint'])\n",
    "# df[df['sessions']=='Race'].tail(50)\n",
    "print('\\n','-'*100, '\\n','df Length is: ', len(df), '\\n','-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33309cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4742a8",
   "metadata": {},
   "source": [
    "<a id='plotsamplelapdata'></a>\n",
    "### Plot a sample race lap-data and weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583ddfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_lap = df_lapWeather[(df_lapWeather['EventName']=='Austrian Grand Prix') &\n",
    "        (df_lapWeather['Team']=='Red Bull Racing') &\n",
    "        (df_lapWeather['session']=='Race') &\n",
    "       (df_lapWeather['eventYear']==2019) &\n",
    "        (df_lapWeather['Driver']=='VER')].sort_values('Time').reset_index(drop=True) #(df_laps['Driver']=='PER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c446f78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,2))\n",
    "plt.plot(sub_lap['LapNumber'],sub_lap['lapTimeSec'])\n",
    "plt.grid()\n",
    "plt.xlabel('Lap Number')\n",
    "plt.ylabel('Lap Time (Sec)')\n",
    "plt.title(sub_lap['EventName'][0]+ '   ' +\n",
    "          str(sub_lap['eventYear'].values[0])+ '   Driver: ' +\n",
    "          sub_lap['Driver'][0])\n",
    "\n",
    "fig = plt.figure(figsize=(12,2))\n",
    "plt.plot(sub_lap['LapNumber'],sub_lap['AirTemp'])\n",
    "plt.grid()\n",
    "plt.xlabel('Lap Number')\n",
    "plt.ylabel('Temp C')\n",
    "\n",
    "fig = plt.figure(figsize=(12,2))\n",
    "plt.plot(sub_lap['LapNumber'],sub_lap['Humidity'])\n",
    "plt.grid()\n",
    "plt.xlabel('Lap Number')\n",
    "plt.ylabel('Humidity %')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf6930f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lap_times(df_sub, event,driver, session):   \n",
    "\n",
    "    \n",
    "    a = 0 #len(df_sub) - df_sub['lapNumber'][-1:].values[0]\n",
    "    b = len(df_sub)\n",
    "    \n",
    "    Compound = df_sub['Compound'][a:b]\n",
    "    \n",
    "    print('Session: ',session, '\\n','driver_name', np.unique(df_sub['Driver']),'\\n', \n",
    "          'Compond: ', np.unique(Compound[Compound.notnull()]))\n",
    "    \n",
    "    lapNumber = np.arange(a,b)\n",
    "    lapTime = df_sub['lapTimeSec']\n",
    "    plot_laptime = lapTime[a:b]\n",
    "    lapTime_hat = df_sub['deg_bias']+df_sub['deg_slope']* df_sub['LapNumber']\n",
    "    lapTime_fuel_corred = df_sub['lapTimeSec'] - df_sub['fuel_slope']*df_sub['LapNumber']\n",
    "    lapTime_hat_fuel_corred = lapTime_hat - df_sub['fuel_slope']*df_sub['LapNumber']\n",
    "    fuel_line = df_sub['fuel_slope']*df_sub['LapNumber'] + df_sub['fuel_bias']\n",
    "    \n",
    "## charts\n",
    "    fig = plt.figure(figsize=(15,3))\n",
    "    plt.plot(df_sub['LapNumber'], lapTime_hat,color='red')\n",
    "    plt.plot(lapNumber, plot_laptime, color='green')\n",
    "    plt.plot(lapNumber[df_sub['large_delta_time']],  \n",
    "             df_sub[df_sub['large_delta_time']]['lapTimeSec'] ,'.',color='black')  \n",
    "    plt.plot(lapNumber, lapTime_hat_fuel_corred, color='silver')\n",
    "    plt.plot(lapNumber, lapTime_fuel_corred, color='gray')\n",
    "    plt.plot(lapNumber, fuel_line, '-', color='tan')\n",
    "    \n",
    "### plot labels, title, etc\n",
    "    top = 105\n",
    "    bot = np.nanmin( plot_laptime) #plot_laptime\n",
    "    print('bot: ',bot)\n",
    "    if (~np.isnan(bot) )&(session!='Qual') :\n",
    "        plt.ylim(bot,top)\n",
    "        d = (top-bot)/10\n",
    "\n",
    "        for ii in range(a,b,5):\n",
    "            plt.text(ii-1,top-4*d , df_sub['Compound'][ii], fontsize = 10) #np.nanmax(plot_laptime)-5\n",
    "#             plt.text(ii-1,top-3*d,df_sub['tyres_condition'][ii], fontsize = 10)\n",
    "            plt.text(ii-1,top-2*d,df_sub['Stint'][ii], fontsize = 10)\n",
    "#             plt.text(ii-1,top-1*d,df_sub['tyres_type'][ii], fontsize = 10)\n",
    "        plt.xticks(lapNumber, df_sub['LapNumber'],rotation=45)\n",
    "        plt.xlabel('LapNumber', fontsize = 16)\n",
    "        plt.title('event: '+event+',    '+'driver: '+driver, fontsize = 14)\n",
    "        plt.ylabel(' time', fontsize = 14)\n",
    "        plt.legend(['stintLapTimeLine','stintLapTime','stintLapTimeLineCorred',\n",
    "                    'regLinePoints','stintLapTimeCorred','FuelLine'],fontsize = 11)\n",
    "\n",
    "        plt.grid(visible=True)\n",
    "        plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72df36ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = np.unique(df['EventName'])\n",
    "\n",
    "for evnt in ['Australian Grand Prix', 'Bahrain Grand Prix' ]: #Australian\n",
    "    drivers = np.unique(df['Driver'][df['EventName']==evnt])\n",
    "    for drvs in ['VER','LEC','PER']:\n",
    "        \n",
    "        sub_df = df[(df['EventName']==evnt) & (df['Driver']==drvs) &  \n",
    "                    (df['session']=='Race') &(df['eventYear']==2019)].sort_values(by = ['LapNumber']).reset_index(drop=True)\n",
    "        if len(sub_df):\n",
    "            plot_lap_times(sub_df,evnt,drvs, 'Race')\n",
    "            \n",
    "        print('*' * 150,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40a6ae7",
   "metadata": {},
   "source": [
    "<a id='mergeLinesSlopAndBias'></a>\n",
    "## Merge lines' slop and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98966041",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = pd.read_csv('../data/semi_final_data.csv')\n",
    "df.drop_duplicates(subset=['fuel_slope', 'fuel_bias', 'deg_slope', 'deg_bias'],keep='first',inplace=True)\n",
    "mergeCols = ['EventName','eventYear','RoundNumber','Driver','Stint','Team', 'fuel_slope', 'fuel_bias', 'deg_slope', 'deg_bias']\n",
    "dd = df_agg.merge(df[mergeCols], how = 'left', on =['EventName','Team','RoundNumber','eventYear','Driver','Stint'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02507aac",
   "metadata": {},
   "source": [
    "### Slopes and bias of current race can not be used as a predictor for the same race\n",
    "Thus lag features should be included for the current race.\n",
    "\n",
    "The focus of this project is to predict Length of Stint One and therefore there is no need to normalize for fuel as all drivers starts the race with full tank.\n",
    "For other Stints we suggest correcting deg_slope based on fuel_slop and before calculating lag features.\n",
    "\n",
    "Users are encouraged to add any additional lag features here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976016c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_create_lag_features(df_sub):\n",
    "    df_sub = df_sub.sort_values(['EventName','RoundNumber'])\n",
    "    \n",
    "    s_m = [np.nan]\n",
    "    b_m =[np.nan]\n",
    "    if len(df_sub)>1:\n",
    "        for ii in range(1,len(df_sub) ):\n",
    "            s_m.append(np.mean(df_sub[:ii-1]['deg_slope']))\n",
    "            b_m.append(np.mean(df_sub[:ii-1]['deg_bias'])) #repeating last race is better\n",
    "\n",
    "    df_sub['lag_slope_mean'] = s_m #df_sub['deg_slope'].rolling(window=2).mean()\n",
    "    df_sub['lag_bias_mean'] = b_m #df_sub['deg_bias'].rolling(window=2).mean()\n",
    "    \n",
    "    return df_sub[['RoundNumber','eventYear','Driver','lag_slope_mean','lag_bias_mean']]\n",
    "\n",
    "dd1 = dd.groupby(['EventName','Compound','Team', 'Stint']).apply(func_create_lag_features).reset_index()\n",
    "dd = dd.merge(dd1, on =['EventName','Compound','Team', 'Stint','RoundNumber','eventYear','Driver'])\n",
    "print('\\n','-'*100, '\\n','df Length is: ', len(dd), '\\n','-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f88b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46c9954",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.to_csv('../data/final_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9365342f",
   "metadata": {},
   "source": [
    "### End of Merge Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774e8ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3906466d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "425061bd4f6c1b850df5ad58d95c5de748ed72fd3c46e84bc23f876a344a0d26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "738b26b3",
   "metadata": {},
   "source": [
    "# OCI Data Science - pull data\n",
    "\n",
    "This notebook provides tools and techniques to pull required data for the project.\n",
    "\n",
    "Using fastF1 API, we'll pull data that involves::\n",
    "- Lap\n",
    "- Weather\n",
    "- Car\n",
    "- Results\n",
    "- Position "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e32e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/datascience/redbull-pit-strategy/notebooks'\n",
    "data_path = '../../redbull-pit-strategy/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "610b8122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(path)\n",
    "import pandas as pd\n",
    "import logging\n",
    "import json\n",
    "import pickle\n",
    "import requests\n",
    "import numpy as np\n",
    "import fastf1\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "fastf1.Cache.enable_cache(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c17ffa1",
   "metadata": {},
   "source": [
    "Now, we create a couple of functions to return data in a structure that we want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b9249a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lap_data(session, schedule, evnt, ses, EventDate):\n",
    "    '''get lap data from a session and\n",
    "       retun as a dataframe\n",
    "    '''\n",
    "    if len(session.laps)==0:\n",
    "        return []\n",
    "    lap = session.laps.to_dict()\n",
    "    lap = pd.DataFrame.from_dict(lap)\n",
    "    lap['RoundNumber'] = schedule['RoundNumber'][schedule['EventName']==evnt].values[0]\n",
    "    lap['EventName'] = evnt\n",
    "    lap['country'] = schedule['Country'][schedule['EventName']==evnt].values[0]\n",
    "    lap['session'] = ses\n",
    "    lap['EventDate'] = schedule[EventDate][schedule['EventName']==evnt].values[0]\n",
    "    return lap\n",
    "\n",
    "def get_weather_data(session, schedule, evnt, ses,EventDate): \n",
    "    '''get weather data from a session and\n",
    "       retun as a dataframe\n",
    "    '''\n",
    "    if len(session.weather_data)==0:\n",
    "        return []\n",
    "    weather = session.weather_data.to_dict()\n",
    "    weather = pd.DataFrame.from_dict(weather)\n",
    "    weather['RoundNumber'] = schedule['RoundNumber'][schedule['EventName']==evnt].values[0]\n",
    "    weather['EventName'] = evnt\n",
    "    weather['country'] = schedule['Country'][schedule['EventName']==evnt].values[0]\n",
    "    weather['session'] = ses\n",
    "    weather['EventDate'] = schedule[EventDate][schedule['EventName']==evnt].values[0]\n",
    "    return weather\n",
    "\n",
    "def get_car_data(session, schedule, evnt, ses,EventDate):\n",
    "    '''get car_data from a session and\n",
    "       retun as a dataframe\n",
    "    '''\n",
    "    if len(session.car_data)==0:\n",
    "        return []\n",
    "    session.weather_data\n",
    "    for ii in session.car_data:\n",
    "        car_data = session.car_data[ii].to_dict()\n",
    "        car_data = pd.DataFrame.from_dict(car_data)\n",
    "        car_data['driver'] = ii\n",
    "    car_data['RoundNumber'] = schedule['RoundNumber'][schedule['EventName']==evnt].values[0]\n",
    "    car_data['EventName'] = evnt\n",
    "    car_data['country'] = schedule['Country'][schedule['EventName']==evnt].values[0]\n",
    "    car_data['session'] = ses\n",
    "    car_data['EventDate'] = schedule[EventDate][schedule['EventName']==evnt].values[0]\n",
    "    return car_data\n",
    "\n",
    "def get_position_data(session, schedule, evnt, ses, EventDate):\n",
    "    '''get position_data from a session and\n",
    "       retun as a dataframe\n",
    "    '''    \n",
    "    if len(session.pos_data)==0:\n",
    "        return []\n",
    "    for ii in session.pos_data:\n",
    "        position = session.pos_data[ii].to_dict()\n",
    "        position = pd.DataFrame.from_dict(position)\n",
    "        position['driver'] = ii\n",
    "    position['RoundNumber'] = schedule['RoundNumber'][schedule['EventName']==evnt].values[0]\n",
    "    position['EventName'] = evnt\n",
    "    position['country'] = schedule['Country'][schedule['EventName']==evnt].values[0]\n",
    "    position['session'] = ses\n",
    "    position['EventDate'] = schedule[EventDate][schedule['EventName']==evnt].values[0]\n",
    "    return position\n",
    "\n",
    "def get_results(session, schedule, evnt, ses, EventDate):\n",
    "    '''get results data from a session and\n",
    "       retun as a dataframe\n",
    "    '''\n",
    "    if len(session.results)==0:\n",
    "        return []\n",
    "    result = session.results.to_dict()\n",
    "    result = pd.DataFrame.from_dict(result).reset_index()\n",
    "    result['RoundNumber'] = schedule['RoundNumber'][schedule['EventName']==evnt].values[0]\n",
    "    result['EventName'] = evnt\n",
    "    result['country'] = schedule['Country'][schedule['EventName']==evnt].values[0]\n",
    "    result['session'] = ses\n",
    "    result['EventDate'] = schedule[EventDate][schedule['EventName']==evnt].values[0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd9f4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull data and store it in the data directory\n",
    "\n",
    "sessionDateMap = {'Race': 'Session5Date',\n",
    "          'Qualifying': 'Session4Date',\n",
    "            'FP1': 'Session1Date',\n",
    "            'FP2': 'Session2Date',\n",
    "            'FP3': 'Session3Date',\n",
    "            'S':  'Session4Date',\n",
    "            'SQ':  'Session4Date'}\n",
    "\n",
    "for year in [2018, 2019, 2020, 2021, 2022]:\n",
    "    laps = []\n",
    "    weathers = []\n",
    "    results = []\n",
    "    \n",
    "    sch = fastf1.get_event_schedule(year).to_dict()\n",
    "    sch = pd.DataFrame.from_dict(sch)\n",
    "\n",
    "    ## year 2022 doesn't have data after June (yet)\n",
    "    if year == 2022:\n",
    "        sch = sch[sch.index<12]\n",
    "        \n",
    "    EventName = [s for s in sch['EventName'] if 'Grand' in s]\n",
    "    \n",
    "    for event in EventName:\n",
    "        for session_type in ['FP1','FP2','FP3','S','SQ','Qualifying','Race']:\n",
    "            \n",
    "            eventDateColName = sessionDateMap[session_type]\n",
    "            \n",
    "            session = None\n",
    "            \n",
    "            try:\n",
    "                session = fastf1.get_session(year, event, session_type) # call fastf1 to extract data\n",
    "            except:\n",
    "                print('Session: {} does not exist {}.'.format(session_type, event))\n",
    "                session = None\n",
    "            if session is not None:\n",
    "                try:\n",
    "                    session.load()\n",
    "                except:\n",
    "                    print('Session: ' + session_type + ' does not provide usable data {}.'.format(event))\n",
    "                    session = None\n",
    "            \n",
    "            # if the session exists, extract all data with auxiliary functions from the above cells\n",
    "            if session is not None:\n",
    "                ## get lap data for a session\n",
    "                laps.append(get_lap_data(session, sch, event, \n",
    "                                         session_type, eventDateColName))\n",
    "\n",
    "                ## get weather data for a session\n",
    "                weathers.append(get_weather_data(session, sch, event, \n",
    "                                                 session_type, eventDateColName))\n",
    "\n",
    "                ## get results for a session\n",
    "                results.append(get_results(session, sch, event, \n",
    "                                           session_type, eventDateColName))\n",
    "\n",
    "\n",
    "    ## save all extracted session data in a year           \n",
    "    file = open('{}{}_{}.pkl'.format(data_path, 'laps', year), 'wb')\n",
    "    pickle.dump(laps,file)\n",
    "    file = open('{}{}_{}.pkl'.format(data_path, 'weathers', year), 'wb')\n",
    "    pickle.dump(weathers,file)\n",
    "    file = open('{}{}_{}.pkl'.format(data_path, 'results', year), 'wb')\n",
    "    pickle.dump(results,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6605084",
   "metadata": {},
   "source": [
    "Now, all that's left to do is to concatenate all relevant pickle files from each type, and save them into a single pickle for each one of the types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06a28226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_data_and_save(data_source, data_path):\n",
    "    '''\n",
    "    e.g. data_source is weather\n",
    "    1. finds all pkl files in the data_path folder\n",
    "    2. concat all\n",
    "    3. saves the in 'data_source'.pickle\n",
    "    '''\n",
    "    data = []\n",
    "    files = os.listdir(data_path)\n",
    "    file = [x for x in files if x.endswith('.pkl') if data_source in x]\n",
    "    \n",
    "    for fl in file:\n",
    "        print(fl)\n",
    "        file = open('{}{}'.format(data_path, fl), 'rb')\n",
    "        data.extend(pickle.load(file))\n",
    "    data = pd.concat(data, axis=0)\n",
    "\n",
    "    file = open('{}{}_data.pickle'.format(data_path, data_source), 'wb')\n",
    "    pickle.dump(data,file)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44fc35a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weathers_2020.pkl\n",
      "weathers_2021.pkl\n",
      "weathers_2018.pkl\n",
      "weathers_2019.pkl\n",
      "weathers_2022.pkl\n",
      "laps_2020.pkl\n",
      "laps_2018.pkl\n",
      "laps_2019.pkl\n",
      "laps_2021.pkl\n",
      "laps_2022.pkl\n",
      "results_2022.pkl\n",
      "results_2019.pkl\n",
      "results_2020.pkl\n",
      "results_2021.pkl\n",
      "results_2018.pkl\n"
     ]
    }
   ],
   "source": [
    "concat_data_and_save('weathers', data_path)\n",
    "concat_data_and_save('laps', data_path)\n",
    "concat_data_and_save('results', data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375b5284",
   "metadata": {},
   "source": [
    "At this point, we've finished the data extraction process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fedcfdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "425061bd4f6c1b850df5ad58d95c5de748ed72fd3c46e84bc23f876a344a0d26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dced21a",
   "metadata": {},
   "source": [
    "### OCI Data Science - Explore data, Join, and clean\n",
    "\n",
    "Before using this notebook users have to download neccessary data. We've collected/downloaded the data in advance by utilizing `00 pull data.ipunb` notebook and saved them to `data` folder.\n",
    "\n",
    "This helps to save time, although data-download may take a few hours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f5ce0d",
   "metadata": {},
   "source": [
    "## Contents:\n",
    "\n",
    "* <a href='#intro'>Introduction</a>\n",
    "* <a href='#weatherdata'>Weather Data</a>\n",
    "* <a href='#lapsdata'>Laps Data</a>\n",
    "* <a href='#resultdata'>Results Data</a>\n",
    "* <a href='#Joindata'>Merging Weather and Lap Data</a>\n",
    "* <a href='#plotsamplelapdata'>Plotting Sample Lap Data</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643d2d07",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "\n",
    "Data has already been saved in **data** folder. The data that interests us has `.pickle` extension, and are currently in raw format, which means that it requires pre-processing and preparation before performing feature extraction and model building.\n",
    "\n",
    "This notebook only focuses on what's in the raw data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b7b5df",
   "metadata": {},
   "source": [
    "#### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51f5256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/datascience/RedBull-Racining-TimeToPit/notebooks'\n",
    "data_path = '../../RedBull-Racining-TimeToPit/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4efbf134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "os.chdir(path)\n",
    "import pandas as pd\n",
    "import logging\n",
    "import json\n",
    "import pickle\n",
    "import requests\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9728f381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.5'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46a1ca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_data_and_save(data_source, data_path):\n",
    "    '''\n",
    "    e.g. data_source is weather\n",
    "    1. finds all pkl files in the data_path folder\n",
    "    2. concat all\n",
    "    3. saves the in 'data_source'.pickle\n",
    "    '''\n",
    "    data = []\n",
    "    files = os.listdir(data_path)\n",
    "    file = [x for x in files if x.endswith('.pkl') if data_source in x]\n",
    "    \n",
    "    for fl in file:\n",
    "        print(fl)\n",
    "        file = open('{}{}'.format(data_path, fl), 'rb')\n",
    "        data.extend(pickle.load(file))\n",
    "    data = pd.concat(data, axis=0)\n",
    "\n",
    "    file = open('{}{}_data.pickle'.format(data_path, data_source), 'wb')\n",
    "    pickle.dump(data,file)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fd2ede5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weathers_2022.pkl\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute '_unpickle_block' on <module 'pandas._libs.internals' from '/opt/conda/lib/python3.8/site-packages/pandas/_libs/internals.cpython-38-x86_64-linux-gnu.so'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mconcat_data_and_save\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweathers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m concat_data_and_save(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlaps\u001b[39m\u001b[38;5;124m'\u001b[39m, data_path)\n\u001b[1;32m      3\u001b[0m concat_data_and_save(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m, data_path)\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mconcat_data_and_save\u001b[0;34m(data_source, data_path)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(fl)\n\u001b[1;32m     14\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(data_path, fl), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m     data\u001b[38;5;241m.\u001b[39mextend(\u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     16\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(data, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     18\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_data.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(data_path, data_source), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute '_unpickle_block' on <module 'pandas._libs.internals' from '/opt/conda/lib/python3.8/site-packages/pandas/_libs/internals.cpython-38-x86_64-linux-gnu.so'>"
     ]
    }
   ],
   "source": [
    "concat_data_and_save('weathers', data_path)\n",
    "concat_data_and_save('laps', data_path)\n",
    "concat_data_and_save('results', data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6895a51b",
   "metadata": {},
   "source": [
    "<a id='weatherdata'></a>\n",
    "## Weather Data\n",
    "Weather data is available at the session level, and its time stamp is not aligned with laps-data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bb81cfc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute '_unpickle_block' on <module 'pandas._libs.internals' from '/opt/conda/lib/python3.8/site-packages/pandas/_libs/internals.cpython-38-x86_64-linux-gnu.so'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(data_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweathers_2018.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m df_weather \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# add eventYear to the dataset\u001b[39;00m\n\u001b[1;32m      4\u001b[0m df_weather[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meventYear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDatetimeIndex(df_weather[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEventDate\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39myear \u001b[38;5;66;03m# get the year\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute '_unpickle_block' on <module 'pandas._libs.internals' from '/opt/conda/lib/python3.8/site-packages/pandas/_libs/internals.cpython-38-x86_64-linux-gnu.so'>"
     ]
    }
   ],
   "source": [
    "file = open('{}{}'.format(data_path, 'weathers_data.pickle'),'rb')\n",
    "df_weather = pickle.load(file)\n",
    "# add eventYear to the dataset\n",
    "df_weather['eventYear'] = pd.DatetimeIndex(df_weather['EventDate']).year # get the year\n",
    "\n",
    "df_weather.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ef7478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average_weather: Get only race sessions, group them by event name, session and date, and get the mean for each one of the groups created for the rest of variables.\n",
    "# avg. airtemp, humidity, pressure...\n",
    "ave_weather = df_weather[df_weather['session']=='Race'].groupby(['EventName','session','EventDate']).mean().reset_index().sort_values(['EventName'])\n",
    "ave_weather.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a25fb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise: display average weather conditions for the coldest raining races in 2021\n",
    "exercise_weather = df_weather[\n",
    "    (df_weather['session']=='Race') &\n",
    "    (df_weather['Rainfall']==True) &\n",
    "    (df_weather['eventYear']==2021)\n",
    "].groupby(['EventName', 'eventYear', 'RoundNumber']).mean().sort_values('AirTemp', ascending=True)\n",
    "exercise_weather.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5465e0aa",
   "metadata": {},
   "source": [
    "### Example: Track temp, ambient temp and humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e991d9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize track temperature, air temperature and humidity %.\n",
    "# Valuable because tire life/performance depends on the track temperature\n",
    "def plot_weather(d_f):\n",
    "\n",
    "    fig = plt.figure(figsize=(12,2))\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    labels = [d_f.loc[x,['EventName']].values[0] +'_'+ \n",
    "              str(pd.DatetimeIndex(d_f.loc[x,['EventDate']]).year.values[0]) \n",
    "              for x in range(len(d_f))]\n",
    "    x = np.arange(len(labels) )\n",
    "    ax.bar(x + 0.00, d_f['AirTemp'], color='b', width=0.10)\n",
    "    ax.bar(x + 0.25, d_f['TrackTemp'], color='r', width=0.10)\n",
    "    ax.bar(x + 0.50, d_f['Humidity'], color='g', width=0.10)\n",
    "    ax.set_xticks(x, labels, rotation=45, fontsize =10)\n",
    "    ax.legend(['AirTemp','TrackTemp','Humidity'])\n",
    "    ax.grid()\n",
    "    plt.title('average weather parameters at different sessions')\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "plot_weather(ave_weather[(ave_weather['EventName']=='Austrian Grand Prix') | \n",
    "    (ave_weather['EventName']=='Abu Dhabi Grand Prix')].reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ef414d",
   "metadata": {},
   "source": [
    "<a id='resultdata'></a>\n",
    "## Results Data\n",
    "\n",
    "Load data and select only `Red Bull Racing` data.\n",
    "\n",
    "Drop non-race and non-qual rows from results data and keeping the following columns:\n",
    "`['Position','FullName','Q1Sec','Q2Sec','Q3Sec', 'RoundNumber','EventName','eventYear','session','TimeSec']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f66e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('{}{}'.format(data_path, 'results_data.pickle'),'rb')\n",
    "df_res = pickle.load(file)\n",
    "\n",
    "df_res['eventYear'] = pd.DatetimeIndex(df_res['EventDate']).year\n",
    "df_res['Q1Sec'] = df_res['Q1']/np.timedelta64(1, 's')\n",
    "df_res['Q2Sec'] = df_res['Q2']/np.timedelta64(1, 's')\n",
    "df_res['Q3Sec'] = df_res['Q3']/np.timedelta64(1, 's')\n",
    "df_res['TimeSec'] = df_res['Time']/np.timedelta64(1, 's')\n",
    "\n",
    "## Selct only Red Bull Racing\n",
    "df_res = df_res[df_res['TeamName']=='Red Bull Racing'] \n",
    "\n",
    "## keep only race and qualifier data\n",
    "df_res = df_res[(df_res['session']=='Race') | (df_res['session']=='Qualifying')]\n",
    "print('df_res size is: ', df_res.shape)\n",
    "print('-'*100,'\\n')\n",
    "\n",
    "df_res= df_res[['Position','GridPosition','FullName','Q1Sec','Q2Sec','Q3Sec','RoundNumber','Abbreviation',\n",
    "                'EventName','eventYear','session','Time','TimeSec','TeamName', 'EventDate']]\n",
    "\n",
    "# Display round number 5, sort by position and year\n",
    "df_res[df_res['RoundNumber']==5].sort_values(['Position','eventYear','Abbreviation'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e569c9cc",
   "metadata": {},
   "source": [
    "<a id='lapsdata'></a>\n",
    "## Laps Data\n",
    "\n",
    "Load data and select only `Red Bull Racing`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ee65a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('{}{}'.format(data_path, 'laps_data.pickle'),'rb')\n",
    "\n",
    "# Columns to drop\n",
    "drop_cols = ['Sector1Time','Sector2Time','Sector3Time',\n",
    "             'Sector1SessionTime','Sector2SessionTime','Sector3SessionTime',\n",
    "            'SpeedI1','SpeedI2','SpeedFL', 'IsAccurate']\n",
    "\n",
    "df_laps = pickle.load(file).drop(drop_cols,axis=1).reset_index(drop=True)\n",
    "\n",
    "df_laps['eventYear'] = pd.DatetimeIndex(df_laps['EventDate']).year\n",
    "df_laps['lapTimeSec'] = df_laps['LapTime']/np.timedelta64(1, 's')\n",
    "\n",
    "# select only RedBull laps\n",
    "df_laps = df_laps[df_laps['Team']=='Red Bull Racing']\n",
    "df_laps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a16543",
   "metadata": {},
   "source": [
    "#### Check Best Qualifying Times\n",
    "\n",
    "Check if best Qual time from `results-data` is the same as best Qual time from `lap-data`\n",
    "Best lap-time from lap Data. are we expecting to see the same best time from `results-data`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453930f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the minimum lap time for each event, year, session, driver -> minTime\n",
    "best_Q = df_laps.groupby(['EventName','eventYear','session','Driver'])['lapTimeSec'].min().reset_index(name='minTime')\n",
    "\n",
    "# example visualization: filter only from (race or qualifying), Abu Dhabi GP and check Sergio's minTimes.\n",
    "best_Q[((best_Q['session']=='Race')|(best_Q['session']=='Qualifying') ) & \n",
    "(best_Q['EventName']=='Abu Dhabi Grand Prix') &\n",
    "(best_Q['Driver']=='PER')].sort_values(['session'])\n",
    "# note only 1 event appearing: it's because 2021 was the first year where this GP happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a20cf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example visualization: filter only from (race or qualifying), Abu Dhabi GP, check Sergio's times for each session.\n",
    "df_res[['TeamName', 'session','EventDate','eventYear','Q1Sec','Q2Sec','Q3Sec','TimeSec']][((df_res['session']=='Race')|(df_res['session']=='Qualifying') ) & \n",
    "(df_res['EventName']=='Abu Dhabi Grand Prix') &\n",
    "(df_res['Abbreviation']=='PER')].sort_values(['session'])\n",
    "\n",
    "# check why we have NaN values: Sergio had a DNF in the race."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23819a91",
   "metadata": {},
   "source": [
    "Best Qual time from results-data and lap-data are the same! \n",
    "We will be using best Qual time as a feature from lap-data. \n",
    "\n",
    "(82.947s for Q3, vs. 82.947 minTime above.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a77005",
   "metadata": {},
   "source": [
    "### End of data exploration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "425061bd4f6c1b850df5ad58d95c5de748ed72fd3c46e84bc23f876a344a0d26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
